{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fo942LMOdlh4"
   },
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:17.819534Z",
     "iopub.status.busy": "2025-05-01T02:23:17.819282Z",
     "iopub.status.idle": "2025-05-01T02:23:38.412677Z",
     "shell.execute_reply": "2025-05-01T02:23:38.411972Z",
     "shell.execute_reply.started": "2025-05-01T02:23:17.819491Z"
    },
    "id": "DokFOdD1dJEl",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim# Create a SummaryWriter instance\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.backends import cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import alexnet, resnet18, resnet34\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf  # 仅用于兼容性\n",
    "import tensorboard as tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIDLJuIXK_vh"
   },
   "source": [
    "**Set Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:38.414485Z",
     "iopub.status.busy": "2025-05-01T02:23:38.413948Z",
     "iopub.status.idle": "2025-05-01T02:23:38.419216Z",
     "shell.execute_reply": "2025-05-01T02:23:38.418546Z",
     "shell.execute_reply.started": "2025-05-01T02:23:38.414465Z"
    },
    "id": "d5PkYfqfK_SA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
    "\n",
    "NUM_CLASSES = 101    # 101 + 1: There is am extra Background class that should be removed \n",
    "\n",
    "BATCH_SIZE = 256    # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
    "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
    "\n",
    "LR = 0.01         # The initial Learning Rate\n",
    "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = 5e-5 # Regularization, you can keep this at the default\n",
    "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
    "\n",
    "STEP_SIZE = 10      # How many epochs before decreasing learning rate (if using a step-down policy)\n",
    "GAMMA = 0.5         # Multiplicative factor for learning rate step-down\n",
    "\n",
    "LOG_FREQUENCY = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gwii0TBHvzh"
   },
   "source": [
    "**Define Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:38.420292Z",
     "iopub.status.busy": "2025-05-01T02:23:38.419936Z",
     "iopub.status.idle": "2025-05-01T02:23:38.441875Z",
     "shell.execute_reply": "2025-05-01T02:23:38.441163Z",
     "shell.execute_reply.started": "2025-05-01T02:23:38.420264Z"
    },
    "id": "QUDdw4j2H0Mc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define transforms for training phase\n",
    "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
    "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
    "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
    "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
    "                                      #transforms.RandomCrop(size=150),\n",
    "                                      #transforms.RandomHorizontalFlip(0.5),\n",
    "                                      #transforms.ColorJitter(brightness=0.3, contrast=0.5, saturation=0.3),\n",
    "                                      #transforms.RandomRotation(degrees=45, center=(0,0)),\n",
    "                                      #transforms.RandomRotation(degrees=45),\n",
    "                                      #transforms.RandomGrayscale(0.5),\n",
    "                                      #transforms.RandomErasing(p=0.5, scale=(0.02, 0.33)),\n",
    "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                                      #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))#Normalizes tensor for pretrained net on ImageNet\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
    "                                      \n",
    "\n",
    "                                      \n",
    "])\n",
    "# Define transforms for the evaluation phase\n",
    "eval_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))#Normalizes tensor for pretrained net on ImageNet\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n",
    "                                      \n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qYIHPzYLY7i"
   },
   "source": [
    "**Prepare Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:38.443559Z",
     "iopub.status.busy": "2025-05-01T02:23:38.443354Z",
     "iopub.status.idle": "2025-05-01T02:23:38.461629Z",
     "shell.execute_reply": "2025-05-01T02:23:38.460959Z",
     "shell.execute_reply.started": "2025-05-01T02:23:38.443544Z"
    },
    "id": "_8AyJAzD1SAa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = '/kaggle/input/caltech101/Caltech101/101_ObjectCategories'\n",
    "#from Caltech101.caltech_dataset import Caltech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:38.462598Z",
     "iopub.status.busy": "2025-05-01T02:23:38.462352Z",
     "iopub.status.idle": "2025-05-01T02:23:38.477825Z",
     "shell.execute_reply": "2025-05-01T02:23:38.477114Z",
     "shell.execute_reply.started": "2025-05-01T02:23:38.462582Z"
    },
    "id": "gJaonXfUh-B2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "\n",
    "class Caltech(VisionDataset):\n",
    "    def __init__(self, root, split='train', transform=None, target_transform=None):\n",
    "        super(Caltech, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "        \n",
    "        self.split = split+\".txt\" # This defines the split you are going to use\n",
    "                                         \n",
    "        self.images=[]\n",
    "        classes=os.listdir(root)\n",
    "        classes.remove('BACKGROUND_Google')\n",
    "        classes.sort()\n",
    "        #create dictionary\n",
    "        n=0\n",
    "        self.Dict={}\n",
    "        for s in classes:\n",
    "          self.Dict[s]=n\n",
    "          n=n+1\n",
    "\n",
    "        file = open(\"/kaggle/input/caltech101/Caltech101/\"+self.split)\n",
    "        for l in file:\n",
    "            line=l.split(\"/\")\n",
    "            classe=line[0]\n",
    "            if classe!='BACKGROUND_Google':\n",
    "              name=line[1].replace(\"\\n\",\"\")\n",
    "              self.images.append(classe+\"/\"+name)\n",
    "        file.close()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      string=self.images[index].split(\"/\")\n",
    "      classe=string[0]\n",
    "      image, label = pil_loader(\"/kaggle/input/caltech101/Caltech101/101_ObjectCategories/\"+self.images[index]), self.Dict[classe]\n",
    "      # Applies preprocessing when accessing the image\n",
    "      if self.transform is not None:\n",
    "        image = self.transform(image)\n",
    " \n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        length = len(self.images) # Provide a way to get the length (number of elements) of the dataset\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:38.478520Z",
     "iopub.status.busy": "2025-05-01T02:23:38.478300Z",
     "iopub.status.idle": "2025-05-01T02:23:38.551075Z",
     "shell.execute_reply": "2025-05-01T02:23:38.550443Z",
     "shell.execute_reply.started": "2025-05-01T02:23:38.478484Z"
    },
    "id": "QfVq_uDHLbsR",
    "outputId": "31225300-a016-460d-8618-87dacafa1f7b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: 2892\n",
      "Valid Dataset: 2892\n",
      "Test Dataset: 2893\n"
     ]
    }
   ],
   "source": [
    "# Prepare Pytorch train/test Datasets\n",
    "\n",
    "train_dataset_pre = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
    "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
    "\n",
    "#della stessa dimensinoe e visto che le classi sono in ordine anche stratificato\n",
    "train_indexes = [x for x in range(len(train_dataset_pre)) if not(x % 2) == 0]\n",
    "val_indexes = [x for x in range(len(train_dataset_pre)) if x % 2 == 0]\n",
    "\n",
    "train_dataset = Subset(train_dataset_pre, train_indexes)\n",
    "val_dataset = Subset(train_dataset_pre, val_indexes)\n",
    "\n",
    "# Check dataset sizes\n",
    "print('Train Dataset: {}'.format(len(train_dataset)))\n",
    "print('Valid Dataset: {}'.format(len(val_dataset)))\n",
    "print('Test Dataset: {}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:38.551906Z",
     "iopub.status.busy": "2025-05-01T02:23:38.551683Z",
     "iopub.status.idle": "2025-05-01T02:23:38.557215Z",
     "shell.execute_reply": "2025-05-01T02:23:38.556471Z",
     "shell.execute_reply.started": "2025-05-01T02:23:38.551891Z"
    },
    "id": "2keqs8LVPD01",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset Caltech\n",
       "    Number of datapoints: 5784\n",
       "    Root location: /kaggle/input/caltech101/Caltech101/101_ObjectCategories\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=True)\n",
       "               CenterCrop(size=(224, 224))\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYEDQ7Z21ldN"
   },
   "source": [
    "**Prepare Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:38.558187Z",
     "iopub.status.busy": "2025-05-01T02:23:38.557959Z",
     "iopub.status.idle": "2025-05-01T02:23:38.571953Z",
     "shell.execute_reply": "2025-05-01T02:23:38.571246Z",
     "shell.execute_reply.started": "2025-05-01T02:23:38.558166Z"
    },
    "id": "VriRw8SI1nle",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbZ1t5Qs2z4j"
   },
   "source": [
    "**Prepare Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:38.573039Z",
     "iopub.status.busy": "2025-05-01T02:23:38.572787Z",
     "iopub.status.idle": "2025-05-01T02:23:39.115220Z",
     "shell.execute_reply": "2025-05-01T02:23:39.114524Z",
     "shell.execute_reply.started": "2025-05-01T02:23:38.573018Z"
    },
    "id": "exHUjtXa22DN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#net=resnet18(pretrained=True)\n",
    "#net=resnet34(pretrained=True)\n",
    "#num_ft = net.fc.in_features\n",
    "#net.fc = nn.Linear(num_ft, NUM_CLASSES)\n",
    "\n",
    "#net = alexnet() # Loading AlexNet model\n",
    "net=alexnet(pretrained=True) #Load pretrined AlexNet on ImageNet\n",
    "\n",
    "# AlexNet has 1000 output neurons, corresponding to the 1000 ImageNet's classes\n",
    "# We need 101 outputs for Caltech-101\n",
    "net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer\n",
    "                                                 # The convolutional layer is nn.Conv2d\n",
    "\n",
    "# We just changed the last layer of AlexNet with a new fully connected layer with 101 outputs\n",
    "\n",
    "\n",
    "\n",
    "######### freeze all the conv and train the fc\n",
    "for layer in net.features.parameters():\n",
    "    layer.requires_grad=False\n",
    "################################################\n",
    "################freeze all the fc \n",
    "# for layer in net.classifier.parameters():\n",
    "#  layer.requires_grad=False\n",
    "###############################################\n",
    "\n",
    "#Note that you can filter the parameters so that only the parameters that requires gradient are passed to the optimizer.\n",
    "for layer in net.parameters():\n",
    "    print(layer.requires_grad)\n",
    "#ft_list = list(net.features)\n",
    "#cl_list = list(net.classifier)\n",
    "#cl_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEyL3H_R4qCf"
   },
   "source": [
    "**Prepare Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:39.117595Z",
     "iopub.status.busy": "2025-05-01T02:23:39.117351Z",
     "iopub.status.idle": "2025-05-01T02:23:39.122524Z",
     "shell.execute_reply": "2025-05-01T02:23:39.121763Z",
     "shell.execute_reply.started": "2025-05-01T02:23:39.117577Z"
    },
    "id": "9sjq00G94tSc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
    "\n",
    "# Choose parameters to optimize\n",
    "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Define scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxYUli9d9uYQ"
   },
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:23:39.123481Z",
     "iopub.status.busy": "2025-05-01T02:23:39.123252Z",
     "iopub.status.idle": "2025-05-01T02:27:17.936691Z",
     "shell.execute_reply": "2025-05-01T02:27:17.935573Z",
     "shell.execute_reply.started": "2025-05-01T02:23:39.123461Z"
    },
    "id": "ZcoQ5fD49yT_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# By default, everything is loaded to cpu\n",
    "net = net.to(DEVICE)  # this will bring the network to GPU if DEVICE is cuda\n",
    "cudnn.benchmark  # Calling this optimizes runtime\n",
    "#######################\n",
    "# Keep the accuracy result \n",
    "myacc = []\n",
    "# Keep the loss\n",
    "myloss = []\n",
    "# Keep the LR\n",
    "mylr = []\n",
    "#######################\n",
    "best_net = net\n",
    "max_acc = 0\n",
    "current_step = 0\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 初始化 TensorBoard 写入器\n",
    "writer = SummaryWriter('runs/cnn_caltech101')\n",
    "\n",
    "# 定义保存模型的路径\n",
    "save_path = '/kaggle/working/best_model.pth'\n",
    "\n",
    "# 在训练循环中记录数据\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_last_lr()))\n",
    "    mylr.append(scheduler.get_last_lr())\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_corrects_train = 0  # To keep track of training accuracy\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        current_step += 1\n",
    "        \n",
    "        # 计算训练集准确率\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_corrects_train += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "    # 记录训练集损失和准确率\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_acc = running_corrects_train / float(len(train_dataset))\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "\n",
    "    # 验证\n",
    "    if epoch % 5 == 0:\n",
    "        net.train(False)\n",
    "        running_corrects_val = 0\n",
    "        running_loss_val = 0.0  # 用于验证集的损失\n",
    "        \n",
    "        for images, labels in tqdm(val_dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss_val += loss.item()\n",
    "            \n",
    "            # 计算验证集准确率\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_corrects_val += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "        # 计算验证集损失和准确率\n",
    "        val_loss = running_loss_val / len(val_dataloader)\n",
    "        val_acc = running_corrects_val / float(len(val_dataset))\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "        if val_acc >= max_acc:\n",
    "            max_acc = val_acc\n",
    "            best_model = net\n",
    "            # 保存最佳模型的权重和参数\n",
    "            #torch.save(best_model.state_dict(), save_path)  # 保存模型\n",
    "\n",
    "        print('Validation Accuracy: {}'.format(val_acc) + ' at epoch: ' + str(epoch+1))\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "# 关闭写入器\n",
    "writer.close()\n",
    "\n",
    "# 启动 TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/cnn_caltech101\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:27:17.938167Z",
     "iopub.status.busy": "2025-05-01T02:27:17.937922Z",
     "iopub.status.idle": "2025-05-01T02:27:27.831456Z",
     "shell.execute_reply": "2025-05-01T02:27:27.830110Z",
     "shell.execute_reply.started": "2025-05-01T02:27:17.938143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "net=best_net\n",
    "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
    "net.train(False) # Set Network to evaluation mode\n",
    "\n",
    "running_corrects = 0\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "  images = images.to(DEVICE)\n",
    "  labels = labels.to(DEVICE)\n",
    "\n",
    "  # Forward Pass\n",
    "  outputs = net(images)\n",
    "\n",
    "  # Get predictions\n",
    "  _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "  # Update Corrects\n",
    "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = running_corrects / float(len(test_dataset))\n",
    "\n",
    "print('Test Accuracy: {}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HM2-MLDL.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7271219,
     "sourceId": 11595176,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
